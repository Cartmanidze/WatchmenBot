using System.Text;
using System.Text.Json;
using WatchmenBot.Models;
using WatchmenBot.Services.Llm;

namespace WatchmenBot.Services;

public class SmartSummaryService
{
    // Token budget for context (roughly 4 chars per token)
    private const int ContextTokenBudget = 6000;
    private const int CharsPerToken = 4;
    private const int ContextCharBudget = ContextTokenBudget * CharsPerToken; // ~24000 chars
    private const int MaxMessagesPerTopic = 12; // Reduced from 20
    private const int MaxTotalTopicMessages = 50; // Hard limit across all topics

    private readonly EmbeddingService _embeddingService;
    private readonly ContextEmbeddingService _contextEmbeddingService;
    private readonly LlmRouter _llmRouter;
    private readonly PromptSettingsStore _promptSettings;
    private readonly DebugService _debugService;
    private readonly ILogger<SmartSummaryService> _logger;

    public SmartSummaryService(
        EmbeddingService embeddingService,
        ContextEmbeddingService contextEmbeddingService,
        LlmRouter llmRouter,
        PromptSettingsStore promptSettings,
        DebugService debugService,
        ILogger<SmartSummaryService> logger)
    {
        _embeddingService = embeddingService;
        _contextEmbeddingService = contextEmbeddingService;
        _llmRouter = llmRouter;
        _promptSettings = promptSettings;
        _debugService = debugService;
        _logger = logger;
    }

    /// <summary>
    /// Generate a smart summary using embeddings for topic extraction and relevance
    /// </summary>
    public async Task<string> GenerateSmartSummaryAsync(
        long chatId,
        List<MessageRecord> messages,
        DateTimeOffset startUtc,
        DateTimeOffset endUtc,
        string periodDescription,
        CancellationToken ct = default)
    {
        var sw = System.Diagnostics.Stopwatch.StartNew();

        // Initialize debug report
        var debugReport = new DebugReport
        {
            Command = "summary",
            ChatId = chatId,
            Query = periodDescription
        };

        // Filter bot messages
        var humanMessages = messages
            .Where(m => !IsBot(m.Username))
            .ToList();

        if (humanMessages.Count == 0)
        {
            return "–ó–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –ª—é–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.";
        }

        _logger.LogInformation("[SmartSummary] Processing {Count} human messages for chat {ChatId}",
            humanMessages.Count, chatId);

        // Step 1: Get diverse representative messages using embeddings
        var diverseMessages = await _embeddingService.GetDiverseMessagesAsync(
            chatId, startUtc, endUtc, limit: 100, ct);

        // Collect debug info for search results
        debugReport.SearchResults = diverseMessages.Select(r => new DebugSearchResult
        {
            Similarity = r.Similarity,
            MessageIds = new[] { r.MessageId },
            Text = r.ChunkText,
            Timestamp = ParseTimestamp(r.MetadataJson)
        }).ToList();

        string summaryContent;

        if (diverseMessages.Count >= 10)
        {
            // Use smart approach: topics + semantic search
            _logger.LogInformation("[SmartSummary] Using embedding-based approach with {Count} diverse messages",
                diverseMessages.Count);
            summaryContent = await GenerateTopicBasedSummaryWithDebugAsync(chatId, humanMessages, diverseMessages, startUtc, endUtc, debugReport, ct);
        }
        else
        {
            // Fallback to traditional approach (not enough embeddings)
            _logger.LogInformation("[SmartSummary] Falling back to traditional approach (only {Count} embeddings)",
                diverseMessages.Count);
            summaryContent = await GenerateTraditionalSummaryWithDebugAsync(humanMessages, debugReport, ct);
        }

        sw.Stop();
        debugReport.LlmTimeMs = sw.ElapsedMilliseconds;

        _logger.LogInformation("[SmartSummary] Generated summary in {Elapsed:F1}s", sw.Elapsed.TotalSeconds);

        // Send debug report to admin
        await _debugService.SendDebugReportAsync(debugReport, ct);

        // Sanitize HTML for Telegram before returning
        var header = $"üìä <b>–û—Ç—á—ë—Ç {periodDescription}</b>\n\n";
        return TelegramHtmlSanitizer.Sanitize(header + summaryContent);
    }

    private static DateTimeOffset? ParseTimestamp(string? metadataJson)
    {
        if (string.IsNullOrEmpty(metadataJson))
            return null;

        try
        {
            using var doc = JsonDocument.Parse(metadataJson);
            if (doc.RootElement.TryGetProperty("DateUtc", out var dateEl))
                return dateEl.GetDateTimeOffset();
        }
        catch { }

        return null;
    }

    private async Task<string> GenerateTopicBasedSummaryWithDebugAsync(
        long chatId,
        List<MessageRecord> allMessages,
        List<SearchResult> diverseMessages,
        DateTimeOffset startUtc,
        DateTimeOffset endUtc,
        DebugReport debugReport,
        CancellationToken ct)
    {
        debugReport.IsMultiStage = true;

        // Step 1: Extract topics from diverse messages
        var topics = await ExtractTopicsAsync(diverseMessages, ct);

        if (topics.Count == 0)
        {
            _logger.LogWarning("[SmartSummary] No topics extracted, using fallback");
            return await GenerateTraditionalSummaryWithDebugAsync(allMessages, debugReport, ct);
        }

        _logger.LogInformation("[SmartSummary] Extracted {Count} topics: {Topics}",
            topics.Count, string.Join(", ", topics));

        // Step 2: For each topic, find relevant messages using hybrid approach
        var topicMessages = new Dictionary<string, List<MessageWithTime>>();
        var seenTexts = new HashSet<string>(); // Global deduplication across topics

        foreach (var topic in topics)
        {
            // Hybrid search: parallel search in both message and context embeddings
            var messageTask = _embeddingService.SearchSimilarInRangeAsync(
                chatId, topic, startUtc, endUtc, limit: 15, ct);
            var contextTask = _contextEmbeddingService.SearchContextAsync(
                chatId, topic, limit: 5, ct);

            await Task.WhenAll(messageTask, contextTask);

            var messageResults = await messageTask;
            var contextResults = await contextTask;

            // Convert context results to SearchResult format
            var contextAsSearchResults = contextResults.Select(cr => new SearchResult
            {
                ChatId = cr.ChatId,
                MessageId = cr.CenterMessageId,
                ChunkIndex = 0,
                ChunkText = cr.ContextText, // Full window with context
                MetadataJson = null,
                Similarity = cr.Similarity,
                Distance = cr.Distance,
                IsNewsDump = false
            }).ToList();

            // Merge results (prioritize context windows for better coherence)
            var allResults = contextAsSearchResults
                .Concat(messageResults)
                .ToList();

            // Filter, deduplicate, and sort by similarity (most relevant first)
            var filtered = allResults
                .Where(m => m.Similarity > 0.3) // Higher threshold for better quality
                .Where(m => !string.IsNullOrWhiteSpace(m.ChunkText))
                .Where(m =>
                {
                    var key = m.ChunkText.Trim().ToLowerInvariant();
                    if (seenTexts.Contains(key)) return false;
                    seenTexts.Add(key);
                    return true;
                })
                .OrderByDescending(m => m.Similarity) // Prioritize by relevance
                .Take(MaxMessagesPerTopic) // Limit per topic
                .Select(ParseMessageWithTime)
                .OrderBy(m => m.Time) // Then sort chronologically for context
                .ToList();

            _logger.LogDebug("[SmartSummary] Topic '{Topic}': {Count} messages ({Context} context + {Message} individual)",
                topic, filtered.Count, contextResults.Count, messageResults.Count);

            topicMessages[topic] = filtered;
        }

        // Step 3: Build stats
        var stats = BuildStats(allMessages);

        // Step 4: Generate two-stage summary (facts first, then humor)
        return await GenerateTwoStageSummaryWithDebugAsync(topicMessages, stats, allMessages, debugReport, ct);
    }

    /// <summary>
    /// Parse SearchResult into MessageWithTime, extracting time from metadata
    /// </summary>
    private static MessageWithTime ParseMessageWithTime(SearchResult result)
    {
        DateTimeOffset time = DateTimeOffset.MinValue;

        if (!string.IsNullOrEmpty(result.MetadataJson))
        {
            try
            {
                using var doc = JsonDocument.Parse(result.MetadataJson);
                if (doc.RootElement.TryGetProperty("DateUtc", out var dateEl))
                {
                    time = dateEl.GetDateTimeOffset();
                }
            }
            catch { /* ignore parsing errors */ }
        }

        return new MessageWithTime
        {
            Text = result.ChunkText,
            Time = time,
            Similarity = result.Similarity
        };
    }

    private class MessageWithTime
    {
        public string Text { get; set; } = string.Empty;
        public DateTimeOffset Time { get; set; }
        public double Similarity { get; set; }
    }

    private async Task<List<string>> ExtractTopicsAsync(List<SearchResult> messages, CancellationToken ct)
    {
        var sampleText = new StringBuilder();
        foreach (var msg in messages.Take(50))
        {
            sampleText.AppendLine(msg.ChunkText);
        }

        var systemPrompt = """
            –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —á–∞—Ç–∞.
            –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–¥–µ–ª–∏—Ç—å 3-7 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º/—Ç–æ–ø–∏–∫–æ–≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è.

            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤–æ–º —Å—Ç—Ä–æ–∫, –±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
            –ü—Ä–∏–º–µ—Ä: ["–†–∞–±–æ—Ç–∞ –∏ –¥–µ–¥–ª–∞–π–Ω—ã", "–ü–æ–ª–∏—Ç–∏–∫–∞", "–ú–µ–º—ã –∏ —à—É—Ç–∫–∏", "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã"]

            –¢–µ–º—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å:
            - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ (–Ω–µ "—Ä–∞–∑–Ω–æ–µ")
            - –ù–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            - –ö–æ—Ä–æ—Ç–∫–∏–º–∏ (2-4 —Å–ª–æ–≤–∞)
            """;

        var userPrompt = $"–°–æ–æ–±—â–µ–Ω–∏—è:\n{sampleText}\n\n–í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã:";

        try
        {
            // –î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–ø–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (–¥–µ—à—ë–≤—ã–π)
            var response = await _llmRouter.CompleteAsync(new LlmRequest
            {
                SystemPrompt = systemPrompt,
                UserPrompt = userPrompt,
                Temperature = 0.3
            }, ct);

            // Parse JSON array
            var cleaned = response.Content.Trim();
            if (cleaned.StartsWith("```"))
            {
                cleaned = cleaned.Split('\n').Skip(1).TakeWhile(l => !l.StartsWith("```")).Aggregate((a, b) => a + b);
            }

            var topics = JsonSerializer.Deserialize<List<string>>(cleaned);
            return topics ?? new List<string>();
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "[SmartSummary] Failed to extract topics");
            return new List<string>();
        }
    }

    /// <summary>
    /// Two-stage generation: first extract facts accurately (low temp), then add humor (high temp)
    /// </summary>
    private async Task<string> GenerateTwoStageSummaryWithDebugAsync(
        Dictionary<string, List<MessageWithTime>> topicMessages,
        ChatStats stats,
        List<MessageRecord> allMessages,
        DebugReport debugReport,
        CancellationToken ct)
    {
        debugReport.StageCount = 2;

        // Build context with token budget
        var contextBuilder = new StringBuilder();
        contextBuilder.AppendLine("–°–¢–ê–¢–ò–°–¢–ò–ö–ê:");
        contextBuilder.AppendLine($"- –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats.TotalMessages}");
        contextBuilder.AppendLine($"- –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {stats.UniqueUsers}");
        contextBuilder.AppendLine($"- –°–æ —Å—Å—ã–ª–∫–∞–º–∏: {stats.MessagesWithLinks}");
        contextBuilder.AppendLine($"- –° –º–µ–¥–∏–∞: {stats.MessagesWithMedia}");
        contextBuilder.AppendLine();

        // Add top active users
        var topUsers = allMessages
            .GroupBy(m => string.IsNullOrWhiteSpace(m.DisplayName) ? m.Username ?? m.FromUserId.ToString() : m.DisplayName)
            .OrderByDescending(g => g.Count())
            .Take(5)
            .Select(g => $"{g.Key}: {g.Count()} —Å–æ–æ–±—â–µ–Ω–∏–π")
            .ToList();

        if (topUsers.Count > 0)
        {
            contextBuilder.AppendLine("–°–ê–ú–´–ï –ê–ö–¢–ò–í–ù–´–ï:");
            foreach (var user in topUsers)
                contextBuilder.AppendLine($"‚Ä¢ {user}");
            contextBuilder.AppendLine();
        }

        // Build topic context with budget awareness
        contextBuilder.AppendLine("–¢–û–ü–ò–ö–ò –ò –°–û–û–ë–©–ï–ù–ò–Ø:");
        var usedChars = contextBuilder.Length;
        var totalMessagesIncluded = 0;
        var messagesExcluded = 0;

        foreach (var (topic, messages) in topicMessages)
        {
            if (messages.Count == 0) continue;
            if (totalMessagesIncluded >= MaxTotalTopicMessages) break;

            var topicHeader = $"\n### {topic}\n";
            if (usedChars + topicHeader.Length > ContextCharBudget) break;

            contextBuilder.Append(topicHeader);
            usedChars += topicHeader.Length;

            foreach (var msg in messages)
            {
                if (totalMessagesIncluded >= MaxTotalTopicMessages)
                {
                    messagesExcluded++;
                    continue;
                }

                var timeStr = msg.Time != DateTimeOffset.MinValue
                    ? $"[{msg.Time.ToLocalTime():HH:mm}] "
                    : "";
                var line = $"{timeStr}{msg.Text}\n";

                if (usedChars + line.Length > ContextCharBudget)
                {
                    messagesExcluded++;
                    continue;
                }

                contextBuilder.Append(line);
                usedChars += line.Length;
                totalMessagesIncluded++;
            }
        }

        var context = contextBuilder.ToString();
        debugReport.ContextSent = context;
        debugReport.ContextMessagesCount = totalMessagesIncluded;
        debugReport.ContextTokensEstimate = usedChars / CharsPerToken;

        _logger.LogInformation("[SmartSummary] Context built: {Included} messages, {Chars}/{Budget} chars, {Excluded} excluded by budget",
            totalMessagesIncluded, usedChars, ContextCharBudget, messagesExcluded);

        // STAGE 1: Extract STRUCTURED facts with low temperature (prevents hallucinations)
        var factsSystemPrompt = """
            –¢—ã ‚Äî —Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —á–∞—Ç–∞. –ò–∑–≤–ª–µ–∫–∏ –§–ê–ö–¢–´ –°–¢–†–û–ì–û –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–∫–∏.

            –í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
            –ï—Å–ª–∏ —Ñ–∞–∫—Ç –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –ø–µ—Ä–µ–ø–∏—Å–∫–∏ ‚Äî –ù–ï –¥–æ–±–∞–≤–ª—è–π –µ–≥–æ.

            –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
            {
              "events": [
                {"what": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è", "who": ["—É—á–∞—Å—Ç–Ω–∏–∫–∏"], "time": "–∫–æ–≥–¥–∞ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ)"}
              ],
              "discussions": [
                {"topic": "—Ç–µ–º–∞", "participants": ["–∏–º–µ–Ω–∞"], "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"}
              ],
              "quotes": [
                {"text": "–ø—Ä—è–º–∞—è —Ü–∏—Ç–∞—Ç–∞", "author": "–∏–º—è", "context": "–æ —á—ë–º"}
              ],
              "heroes": [
                {"name": "–∏–º—è", "why": "—á–µ–º –æ—Ç–ª–∏—á–∏–ª—Å—è (—Å–º–µ—à–Ω–æ/–≥–ª—É–ø–æ/–∫—Ä—É—Ç–æ)"}
              ]
            }

            –ú–∞–∫—Å–∏–º—É–º 5 —Å–æ–±—ã—Ç–∏–π, 5 –æ–±—Å—É–∂–¥–µ–Ω–∏–π, 5 —Ü–∏—Ç–∞—Ç, 3 –≥–µ—Ä–æ—è.
            """;

        var stage1Sw = System.Diagnostics.Stopwatch.StartNew();
        var factsResponse = await _llmRouter.CompleteWithFallbackAsync(
            new LlmRequest
            {
                SystemPrompt = factsSystemPrompt,
                UserPrompt = context,
                Temperature = 0.1 // Very low for accuracy
            },
            preferredTag: null, // Use default (cheaper) provider for facts
            ct: ct);
        stage1Sw.Stop();

        debugReport.Stages.Add(new DebugStage
        {
            StageNumber = 1,
            Name = "Facts (JSON)",
            Temperature = 0.1,
            SystemPrompt = factsSystemPrompt,
            UserPrompt = context,
            Response = factsResponse.Content,
            Tokens = factsResponse.TotalTokens,
            TimeMs = stage1Sw.ElapsedMilliseconds
        });

        _logger.LogDebug("[SmartSummary] Stage 1 (structured facts) complete, {Length} chars", factsResponse.Content.Length);

        // STAGE 2: Add humor based ONLY on structured facts
        var settings = await _promptSettings.GetSettingsAsync("summary");

        var humorSystemPrompt = $"""
            {settings.SystemPrompt}

            –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
            1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ JSON –Ω–∏–∂–µ
            2. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π, –∏–º—ë–Ω, —Ü–∏—Ç–∞—Ç
            3. –¶–∏—Ç–∞—Ç—ã –±–µ—Ä–∏ –î–û–°–õ–û–í–ù–û –∏–∑ –ø–æ–ª—è "quotes"
            4. –ì–µ—Ä–æ–µ–≤ –¥–Ω—è –±–µ—Ä–∏ –∏–∑ –ø–æ–ª—è "heroes"
            5. –î–æ–±–∞–≤–ª—è–π —é–º–æ—Ä –∏ –º–∞—Ç –∫ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú —Ñ–∞–∫—Ç–∞–º
            """;

        var humorUserPrompt = $"""
            –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ï –§–ê–ö–¢–´ (JSON):
            {factsResponse.Content}

            –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
            - –°–æ–æ–±—â–µ–Ω–∏–π: {stats.TotalMessages}
            - –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {stats.UniqueUsers}

            –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Å–∞–º–º–∞—Ä–∏ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –∏–∑ system prompt.
            –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –≤—ã—à–µ!
            """;

        var stage2Sw = System.Diagnostics.Stopwatch.StartNew();
        var finalResponse = await _llmRouter.CompleteWithFallbackAsync(
            new LlmRequest
            {
                SystemPrompt = humorSystemPrompt,
                UserPrompt = humorUserPrompt,
                Temperature = 0.6 // Slightly lower than before (was 0.7)
            },
            preferredTag: settings.LlmTag,
            ct: ct);
        stage2Sw.Stop();

        debugReport.Stages.Add(new DebugStage
        {
            StageNumber = 2,
            Name = "Humor",
            Temperature = 0.6,
            SystemPrompt = humorSystemPrompt,
            UserPrompt = humorUserPrompt,
            Response = finalResponse.Content,
            Tokens = finalResponse.TotalTokens,
            TimeMs = stage2Sw.ElapsedMilliseconds
        });

        // Set final debug info
        debugReport.SystemPrompt = humorSystemPrompt;
        debugReport.UserPrompt = humorUserPrompt;
        debugReport.LlmProvider = finalResponse.Provider;
        debugReport.LlmModel = finalResponse.Model;
        debugReport.LlmTag = settings.LlmTag;
        debugReport.Temperature = 0.6;
        debugReport.LlmResponse = finalResponse.Content;
        debugReport.PromptTokens = factsResponse.PromptTokens + finalResponse.PromptTokens;
        debugReport.CompletionTokens = factsResponse.CompletionTokens + finalResponse.CompletionTokens;
        debugReport.TotalTokens = factsResponse.TotalTokens + finalResponse.TotalTokens;

        _logger.LogDebug("[SmartSummary] Stage 2 (humor) complete. Provider: {Provider}", finalResponse.Provider);

        return finalResponse.Content;
    }

    private async Task<string> GenerateTraditionalSummaryWithDebugAsync(List<MessageRecord> messages, DebugReport debugReport, CancellationToken ct)
    {
        debugReport.IsMultiStage = true;
        debugReport.StageCount = 2;

        // Uniform sampling with reduced sample size for better focus
        var sample = SampleMessagesUniformly(messages, maxMessages: 200);

        var convo = new StringBuilder();
        foreach (var m in sample)
        {
            var name = string.IsNullOrWhiteSpace(m.DisplayName)
                ? (string.IsNullOrWhiteSpace(m.Username) ? m.FromUserId.ToString() : m.Username)
                : m.DisplayName;
            var text = string.IsNullOrWhiteSpace(m.Text) ? $"[{m.MessageType}]" : m.Text!.Replace("\n", " ");
            convo.AppendLine($"[{m.DateUtc.ToLocalTime():HH:mm}] {name}: {text}");
        }

        var stats = BuildStats(messages);

        // Add top active users
        var topUsers = messages
            .GroupBy(m => string.IsNullOrWhiteSpace(m.DisplayName) ? m.Username ?? m.FromUserId.ToString() : m.DisplayName)
            .OrderByDescending(g => g.Count())
            .Take(5)
            .Select(g => $"{g.Key}: {g.Count()}")
            .ToList();

        // Two-stage approach with STRUCTURED JSON for facts (prevents hallucinations)
        var factsSystemPrompt = """
            –¢—ã ‚Äî —Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —á–∞—Ç–∞. –ò–∑–≤–ª–µ–∫–∏ –§–ê–ö–¢–´ –°–¢–†–û–ì–û –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–∫–∏.

            –í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
            –ï—Å–ª–∏ —Ñ–∞–∫—Ç –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –ø–µ—Ä–µ–ø–∏—Å–∫–æ–π ‚Äî –ù–ï –¥–æ–±–∞–≤–ª—è–π –µ–≥–æ.

            –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
            {
              "events": [
                {"what": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è", "who": ["—É—á–∞—Å—Ç–Ω–∏–∫–∏"]}
              ],
              "discussions": [
                {"topic": "—Ç–µ–º–∞", "participants": ["–∏–º–µ–Ω–∞"], "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"}
              ],
              "quotes": [
                {"text": "–ø—Ä—è–º–∞—è —Ü–∏—Ç–∞—Ç–∞", "author": "–∏–º—è"}
              ],
              "heroes": [
                {"name": "–∏–º—è", "why": "—á–µ–º –æ—Ç–ª–∏—á–∏–ª—Å—è"}
              ]
            }

            –ú–∞–∫—Å–∏–º—É–º 5 —Å–æ–±—ã—Ç–∏–π, 5 –æ–±—Å—É–∂–¥–µ–Ω–∏–π, 5 —Ü–∏—Ç–∞—Ç, 3 –≥–µ—Ä–æ—è.
            """;

        var contextPrompt = new StringBuilder();
        contextPrompt.AppendLine($"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats.TotalMessages} —Å–æ–æ–±—â–µ–Ω–∏–π, {stats.UniqueUsers} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤");
        contextPrompt.AppendLine($"–ê–∫—Ç–∏–≤–Ω—ã–µ: {string.Join(", ", topUsers)}");
        contextPrompt.AppendLine();
        contextPrompt.AppendLine("–ü–µ—Ä–µ–ø–∏—Å–∫–∞:");
        contextPrompt.AppendLine(convo.ToString());

        var context = contextPrompt.ToString();
        debugReport.ContextSent = context;
        debugReport.ContextMessagesCount = sample.Count;
        debugReport.ContextTokensEstimate = context.Length / 4;

        var stage1Sw = System.Diagnostics.Stopwatch.StartNew();
        var factsResponse = await _llmRouter.CompleteWithFallbackAsync(
            new LlmRequest
            {
                SystemPrompt = factsSystemPrompt,
                UserPrompt = context,
                Temperature = 0.1  // Very low for accuracy
            },
            preferredTag: null,
            ct: ct);
        stage1Sw.Stop();

        debugReport.Stages.Add(new DebugStage
        {
            StageNumber = 1,
            Name = "Facts (JSON)",
            Temperature = 0.1,
            SystemPrompt = factsSystemPrompt,
            UserPrompt = context,
            Response = factsResponse.Content,
            Tokens = factsResponse.TotalTokens,
            TimeMs = stage1Sw.ElapsedMilliseconds
        });

        // Stage 2: Add humor based ONLY on structured JSON facts
        var settings = await _promptSettings.GetSettingsAsync("summary");

        var humorSystemPrompt = $"""
            {settings.SystemPrompt}

            –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
            1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ JSON –Ω–∏–∂–µ
            2. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π, –∏–º—ë–Ω, —Ü–∏—Ç–∞—Ç
            3. –¶–∏—Ç–∞—Ç—ã –±–µ—Ä–∏ –î–û–°–õ–û–í–ù–û –∏–∑ –ø–æ–ª—è "quotes"
            4. –ì–µ—Ä–æ–µ–≤ –¥–Ω—è –±–µ—Ä–∏ –∏–∑ –ø–æ–ª—è "heroes"
            5. –î–æ–±–∞–≤–ª—è–π —é–º–æ—Ä –∫ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú —Ñ–∞–∫—Ç–∞–º
            """;

        var humorUserPrompt = $"""
            –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ï –§–ê–ö–¢–´ (JSON):
            {factsResponse.Content}

            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats.TotalMessages} —Å–æ–æ–±—â–µ–Ω–∏–π, {stats.UniqueUsers} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤

            –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON!
            """;

        var stage2Sw = System.Diagnostics.Stopwatch.StartNew();
        var response = await _llmRouter.CompleteWithFallbackAsync(
            new LlmRequest
            {
                SystemPrompt = humorSystemPrompt,
                UserPrompt = humorUserPrompt,
                Temperature = 0.6
            },
            preferredTag: settings.LlmTag,
            ct: ct);
        stage2Sw.Stop();

        debugReport.Stages.Add(new DebugStage
        {
            StageNumber = 2,
            Name = "Humor",
            Temperature = 0.6,
            SystemPrompt = humorSystemPrompt,
            UserPrompt = humorUserPrompt,
            Response = response.Content,
            Tokens = response.TotalTokens,
            TimeMs = stage2Sw.ElapsedMilliseconds
        });

        // Set final debug info
        debugReport.SystemPrompt = humorSystemPrompt;
        debugReport.UserPrompt = humorUserPrompt;
        debugReport.LlmProvider = response.Provider;
        debugReport.LlmModel = response.Model;
        debugReport.LlmTag = settings.LlmTag;
        debugReport.Temperature = 0.6;
        debugReport.LlmResponse = response.Content;
        debugReport.PromptTokens = factsResponse.PromptTokens + response.PromptTokens;
        debugReport.CompletionTokens = factsResponse.CompletionTokens + response.CompletionTokens;
        debugReport.TotalTokens = factsResponse.TotalTokens + response.TotalTokens;

        return response.Content;
    }

    /// <summary>
    /// Sample messages uniformly across time period to capture beginning, middle and end
    /// </summary>
    private static List<MessageRecord> SampleMessagesUniformly(List<MessageRecord> messages, int maxMessages)
    {
        if (messages.Count <= maxMessages)
            return messages;

        var result = new List<MessageRecord>();
        var step = (double)messages.Count / maxMessages;

        for (var i = 0; i < maxMessages; i++)
        {
            var index = (int)(i * step);
            if (index < messages.Count)
                result.Add(messages[index]);
        }

        return result;
    }

    private static ChatStats BuildStats(List<MessageRecord> messages)
    {
        return new ChatStats
        {
            TotalMessages = messages.Count,
            UniqueUsers = messages.Select(m => m.FromUserId).Distinct().Count(),
            MessagesWithLinks = messages.Count(m => m.HasLinks),
            MessagesWithMedia = messages.Count(m => m.HasMedia)
        };
    }

    private static bool IsBot(string? username)
    {
        if (string.IsNullOrWhiteSpace(username))
            return false;

        return username.EndsWith("Bot", StringComparison.OrdinalIgnoreCase) ||
               username.EndsWith("_bot", StringComparison.OrdinalIgnoreCase) ||
               username.Equals("GroupAnonymousBot", StringComparison.OrdinalIgnoreCase) ||
               username.Equals("Channel_Bot", StringComparison.OrdinalIgnoreCase);
    }

    private class ChatStats
    {
        public int TotalMessages { get; set; }
        public int UniqueUsers { get; set; }
        public int MessagesWithLinks { get; set; }
        public int MessagesWithMedia { get; set; }
    }
}
